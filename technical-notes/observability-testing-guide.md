# Observability Testing Pattern Guide

## ğŸ¯ **Overview**

This guide provides a standardized pattern for testing observability implementations across projects. It ensures comprehensive coverage of span creation, error handling, and graceful degradation scenarios.

## ğŸ“‹ **Core Testing Principles**

### 1. **Mock External Dependencies**
- Always mock the observability library (ddtrace, OpenTelemetry, etc.)
- Mock at the module level to avoid import issues
- Use proper type hints and specifications

### 2. **Test Both Happy Path and Edge Cases**
- Active span scenarios
- No active span scenarios (graceful degradation)
- Various data types and edge cases

### 3. **Verify Actual Calls**
- Don't just test that methods don't crash
- Verify the exact calls made to the underlying library
- Check parameter values and call sequences

## ğŸ—ï¸ **Test Structure Pattern**

### **File Organization**
```
tests/
â”œâ”€â”€ unit/
â”‚   â””â”€â”€ frameworks/
â”‚       â””â”€â”€ observability/
â”‚           â””â”€â”€ test_observability_service.py
```

### **Test Class Structure**
```python
class TestObservabilityManager:
    """Test suite for ObservabilityManager."""
    
    def setup_method(self):
        """Set up test fixtures for each test."""
        # Initialize your observability manager
        # Create mock objects
    
    # Group tests by method being tested
    # Use descriptive test names that explain the scenario
```

## ğŸ§ª **Required Test Categories**

### **1. Span Creation Tests**

#### **Basic Functionality**
- âœ… `test_set_span_with_active_span` - Normal operation
- âœ… `test_set_span_with_no_active_span` - Graceful degradation

#### **Data Type Coverage**
- âœ… `test_set_span_with_different_data_types` - Various data types
- âœ… `test_set_span_with_empty_string_key` - Edge case handling
- âœ… `test_set_span_with_unicode_characters` - International support

#### **Multiple Operations**
- âœ… `test_multiple_set_span_calls` - Sequential operations

### **2. Error Handling Tests**

#### **Basic Error Scenarios**
- âœ… `test_set_span_error_with_active_span` - Normal error handling
- âœ… `test_set_span_error_with_no_active_span` - Graceful degradation

#### **Exception Type Coverage**
- âœ… `test_set_span_error_with_different_exception_types` - Various exceptions
- âœ… `test_set_span_error_with_exception_without_message` - Empty messages
- âœ… `test_set_span_error_with_exception_with_complex_message` - Special characters

### **3. Integration Tests**
- âœ… `test_set_span_and_set_span_error_sequence` - Combined operations
- âœ… `test_observability_manager_implements_interface` - Contract compliance

## ğŸ”§ **Implementation Template**

### **Step 1: Mock Setup**
```python
import sys
from types import ModuleType
from unittest.mock import MagicMock, patch, call

# Mock observability library before importing your manager
# Replace 'ddtrace' with your observability library (opentelemetry, etc.)
mock_observability_lib = ModuleType('ddtrace')
mock_tracer = MagicMock()
mock_observability_lib.tracer = mock_tracer
sys.modules['ddtrace'] = mock_observability_lib

from your_project.observability import ObservabilityManager  # noqa: E402
```

### **Step 2: Test Class Setup**
```python
class TestObservabilityManager:
    """Test suite for ObservabilityManager."""

    def setup_method(self):
        """Set up test fixtures."""
        self.observability_manager = ObservabilityManager()
        self.mock_span = MagicMock()
```

### **Step 3: Basic Test Pattern**
```python
@patch('your_project.observability.manager.tracer')
def test_set_span_with_active_span(self, mock_tracer):
    """Test set_span when there's an active span."""
    # Arrange
    mock_tracer.current_span.return_value = self.mock_span
    key = "test_key"
    value = "test_value"

    # Act
    self.observability_manager.set_span(key, value)

    # Assert
    mock_tracer.current_span.assert_called_once()
    self.mock_span.set_tag.assert_called_once_with(key, value)
```

## ğŸ“Š **Test Data Patterns**

### **Data Type Test Cases**
```python
test_cases = [
    ("string", "hello"),
    ("integer", 42),
    ("float", 3.14),
    ("boolean", True),
    ("list", [1, 2, 3]),
    ("dict", {"key": "value"}),
    ("none", None),
]
```

### **Exception Type Test Cases**
```python
test_cases = [
    (ValueError("Value error"), "ValueError"),
    (TypeError("Type error"), "TypeError"),
    (RuntimeError("Runtime error"), "RuntimeError"),
    (KeyError("Key error"), "KeyError"),
    (IndexError("Index error"), "IndexError"),
]
```

### **Edge Case Test Cases**
```python
edge_cases = [
    ("empty_string", ""),
    ("unicode_key", "user_name_Ã©mojis"),
    ("unicode_value", "JosÃ© ğŸš€"),
    ("special_chars", "Error: !@#$%^&*()_+-=[]{}|;':\",./<>?"),
]
```

## ğŸ¯ **Assertion Patterns**

### **Single Call Verification**
```python
mock_tracer.current_span.assert_called_once()
self.mock_span.set_tag.assert_called_once_with(key, value)
```

### **Multiple Call Verification**
```python
self.mock_span.set_tag.assert_has_calls([
    call("key1", "value1"),
    call("key2", "value2"),
    call("key3", "value3")
])
```

### **Error State Verification**
```python
assert self.mock_span.error == 1
self.mock_span.set_tag.assert_has_calls([
    call("error", True),
    call("error.type", "ValueError"),
    call("error.message", "Invalid input")
])
```

### **No-Call Verification**
```python
mock_tracer.current_span.assert_called_once()
self.mock_span.set_tag.assert_not_called()
```

## ğŸ”„ **Mock Reset Pattern**

For tests with multiple iterations:
```python
for test_case in test_cases:
    # Reset mock for each test case
    self.mock_span.reset_mock()
    
    # Run your test
    self.observability_manager.method(test_case)
    
    # Verify results
    self.mock_span.set_tag.assert_called_with(expected_args)
```

## ğŸ“ **Test Naming Convention**

### **Pattern**: `test_{method_name}_with_{scenario}`

**Examples**:
- `test_set_span_with_active_span`
- `test_set_span_with_no_active_span`
- `test_set_span_error_with_different_exception_types`
- `test_multiple_set_span_calls`

## ğŸš€ **Coverage Requirements**

### **Minimum Coverage Targets**
- **Line Coverage**: 100%
- **Branch Coverage**: 100%
- **Method Coverage**: 100%

### **Coverage Verification**
```bash
# Run tests with coverage
pytest tests/unit/observability/ --cov=src/observability --cov-report=term-missing

# Ensure 100% coverage
pytest tests/unit/observability/ --cov=src/observability --cov-fail-under=100
```

## ğŸ” **Quality Checklist**

### **Before Submitting Tests**
- [ ] All happy path scenarios covered
- [ ] All error scenarios covered
- [ ] Edge cases tested (empty strings, unicode, special chars)
- [ ] Graceful degradation verified (no active span)
- [ ] Multiple operation sequences tested
- [ ] Interface compliance verified
- [ ] 100% code coverage achieved
- [ ] All tests pass consistently
- [ ] Mock setup is clean and isolated
- [ ] Test names are descriptive and follow convention

## ğŸ¨ **Customization Guidelines**

### **For Different Observability Libraries**

**OpenTelemetry**:
```python
# Replace ddtrace with opentelemetry
mock_otel = ModuleType('opentelemetry')
mock_trace = MagicMock()
mock_otel.trace = mock_trace
sys.modules['opentelemetry'] = mock_otel
```

**Jaeger**:
```python
# Replace ddtrace with jaeger_client
mock_jaeger = ModuleType('jaeger_client')
mock_tracer = MagicMock()
mock_jaeger.Tracer = mock_tracer
sys.modules['jaeger_client'] = mock_jaeger
```

### **For Different Methods**

Adapt the test patterns for your specific observability interface:
- `set_tag` â†’ `add_attribute`
- `set_span_error` â†’ `record_exception`
- `current_span` â†’ `get_current_span`

## ğŸ“š **Additional Resources**

### **Best Practices**
1. **Isolation**: Each test should be independent
2. **Clarity**: Test names should explain the scenario
3. **Completeness**: Cover all code paths and edge cases
4. **Maintainability**: Use patterns and avoid duplication
5. **Performance**: Tests should run quickly

### **Common Pitfalls to Avoid**
- âŒ Not mocking external dependencies
- âŒ Testing implementation details instead of behavior
- âŒ Incomplete edge case coverage
- âŒ Not verifying actual calls to underlying library
- âŒ Ignoring graceful degradation scenarios

---

## ğŸ¯ **Summary**

This pattern ensures your observability layer is:
- **Reliable**: Comprehensive test coverage catches regressions
- **Robust**: Edge cases and error scenarios are handled
- **Maintainable**: Consistent patterns across projects
- **Production-Ready**: Verified behavior under all conditions

Follow this guide for every observability implementation to maintain consistent quality and reliability across all your projects.
